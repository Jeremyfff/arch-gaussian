{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import math\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from RePaint import conf_mgt\n",
    "from RePaint.utils import yamlread\n",
    "from RePaint.guided_diffusion import dist_util"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ],
   "id": "a1bad21949a07f0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RePaint.guided_diffusion.script_util import (\n",
    "    NUM_CLASSES,\n",
    "    model_and_diffusion_defaults,\n",
    "    classifier_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    create_classifier,\n",
    "    select_args,\n",
    ")  # noqa: E402"
   ],
   "id": "40d97194af636ef4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def toU8(sample):\n",
    "    if sample is None:\n",
    "        return sample\n",
    "\n",
    "    sample = ((sample + 1) * 127.5).clamp(0, 255).to(th.uint8)\n",
    "    sample = sample.permute(0, 2, 3, 1)\n",
    "    sample = sample.contiguous()\n",
    "    sample = sample.detach().cpu().numpy()\n",
    "    return sample\n"
   ],
   "id": "1b33e945287c78ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_image(tensor: th.Tensor):\n",
    "    tensor = th.clamp(tensor, -1.0, 1.0)\n",
    "    img_arr = tensor.detach().cpu().squeeze().numpy() * 0.5 + 0.5  # remap to 0 to 1\n",
    "    pil_image = Image.fromarray((img_arr * 255).astype('uint8').transpose((1, 2, 0)))\n",
    "    return pil_image\n"
   ],
   "id": "6e265a76bfbe768e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## using repaint manager",
   "id": "f140d856853c687"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RePaint.repaint_manager import RepaintManager\n",
    "rm = RepaintManager(conf_path=\"./Repaint/confs/test.yml\")\n"
   ],
   "id": "264e51070679508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 从默认路径获取\n",
    "# gt, gt_keep_mask = rm.debug_get_gt_and_gt_keep_mask()"
   ],
   "id": "5218e2d7eca86e66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# print(gt_keep_mask.shape)",
   "id": "6b57b1e3e627f1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 从本地文件获取\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_image_from_path(path:str):\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    # 定义转换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # 将图像调整为指定的大小\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 将像素值归一化到[-1, 1]\n",
    "    ])\n",
    "\n",
    "    image = transform(image).unsqueeze(0) \n",
    "    return image\n",
    "\n",
    "gt = load_image_from_path(\"./gt.png\")\n",
    "gt_keep_mask = load_image_from_path(\"./gt_keep_mask.png\") * 0.5 + 0.5"
   ],
   "id": "2df015fee709c757",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dffa252b06b8bc08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tensor_to_image(gt)",
   "id": "8b036917ac67ca82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tensor_to_image(gt_keep_mask)\n",
   "id": "cb096fcb4f573e9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rm.conf_arg.schedule_jump_params['t_T']",
   "id": "6275e5d94518a6fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(gt.device)",
   "id": "ee7e9c708c160255",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred_xstart = None\n",
    "sample = None\n",
    "\n",
    "sample, pred_xstart, out, noise, part2 = rm.take_one_sample(gt, gt_keep_mask, sample, 123)\n",
    "tensor_to_image(pred_xstart)"
   ],
   "id": "5553011f7cec654a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "211268fa5d109b75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 手动loop",
   "id": "b8ff1553fb3cd0f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "import torch as th\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def get_combined_image(img1:th.Tensor,\n",
    "                img2: th.Tensor,\n",
    "                img1_name:str,\n",
    "                img2_name:str):\n",
    "    # 创建转换函数，将 tensor 转换为 PIL 图像\n",
    "    tensor_to_pil = transforms.ToPILImage()\n",
    "\n",
    "    img11 = img1 * 0.5 + 0.5\n",
    "    img22 = img2 * 0.5 + 0.5\n",
    "    img11 = th.clamp(img11, 0, 1)\n",
    "    img22 = th.clamp(img22, 0, 1)\n",
    "    # 创建两个 PIL 图像对象\n",
    "    pil_image1 = tensor_to_pil(img11.squeeze(0))\n",
    "    pil_image2 = tensor_to_pil(img22.squeeze(0))\n",
    "\n",
    "    # 在图像上写上名字\n",
    "    font = ImageFont.load_default()\n",
    "    draw1 = ImageDraw.Draw(pil_image1)\n",
    "    draw2 = ImageDraw.Draw(pil_image2)\n",
    "\n",
    "    draw1.text((10, 10), img1_name, font=font, fill=(255, 255, 255, 128))\n",
    "    draw2.text((10, 10), img2_name, font=font, fill=(255, 255, 255, 128))\n",
    "\n",
    "    # 创建一个新的图片，将两张图片拼接在一起\n",
    "    combined_image = Image.new('RGB', (512, 256))\n",
    "    combined_image.paste(pil_image1, (0, 0))\n",
    "    combined_image.paste(pil_image2, (256, 0))\n",
    "\n",
    "    return combined_image"
   ],
   "id": "291b82bbb561f4e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "42a88f5a47aea113",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred_xstart = None\n",
    "sample = None\n",
    "t = 125\n"
   ],
   "id": "93210138428c1bc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(80)):\n",
    "    # print(f\"curr_t = {t}\")\n",
    "    sample, pred_xstart, out, noise, part2 = rm.take_one_sample(gt, gt_keep_mask, sample, t)\n",
    "    t = t - 1\n",
    "    \n",
    "get_combined_image(sample, pred_xstart, \"sample\", \"pred_xstart\")"
   ],
   "id": "b6f3eed0deec30a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 手动计算sample\n",
    "tensor_to_image(out['mean'] + part2)"
   ],
   "id": "f1bdcead89219e2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 手动计算out['mean']\n",
    "\n",
    "\n",
    "tt = th.tensor([t] * gt.shape[0], device=rm.device)\n",
    "model_mean, _, _ = rm.diffusion.q_posterior_mean_variance(x_start=pred_xstart, x_t=sample, t=tt)\n",
    "tensor_to_image(model_mean)"
   ],
   "id": "9c2efbe8c706821c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val = th.exp(0.5 * out[\"log_variance\"])\n",
    "print(th.min(val), th.max(val))\n",
    "tensor_to_image((val - 0.1204) * 1000)"
   ],
   "id": "9d2c5af71c7c69d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 尝试自己写添加噪声的方法\n",
    "\n",
    "pred_xstart = None\n",
    "sample = th.randn_like(gt, device=rm.device)\n",
    "t = 124\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(60)):\n",
    "    # print(f\"curr_t = {t}\")\n",
    "    image_after_step, pred_xstart, out, noise, part2 = rm.take_one_sample(gt, gt_keep_mask, sample, t)\n",
    "    # we do not use image_after_step\n",
    "    tt = th.tensor([t] * gt.shape[0], device=rm.device)\n",
    "    model_mean, _, _ = rm.diffusion.q_posterior_mean_variance(x_start=pred_xstart, x_t=sample, t=tt)\n",
    "    nonzero_mask = (\n",
    "                (tt != 0).float().view(-1, *([1] * (len(sample.shape) - 1)))\n",
    "            )\n",
    "    sample = model_mean + nonzero_mask * th.exp(0.5 * out[\"log_variance\"]) * noise\n",
    "    \n",
    "    t = t - 1\n",
    "    \n",
    "get_combined_image(sample, pred_xstart, \"sample\", \"pred_xstart\")"
   ],
   "id": "f5e859fd9f02bb88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 尝试自己写添加噪声的方法2\n",
    "\n",
    "pred_xstart = None\n",
    "sample = th.randn_like(gt, device=rm.device)\n",
    "t = 124\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(120)):\n",
    "    # print(f\"curr_t = {t}\")\n",
    "    image_after_step, pred_xstart, out, _, _ = rm.take_one_sample(gt, gt_keep_mask, sample, t)\n",
    "    # we do not use image_after_step\n",
    "    tt = th.tensor([t] * gt.shape[0], device=rm.device)\n",
    "    model_mean, posterior_variance, posterior_log_variance_clipped = rm.diffusion.q_posterior_mean_variance(x_start=pred_xstart, x_t=sample, t=tt)\n",
    "    nonzero_mask = (\n",
    "                (tt != 0).float().view(-1, *([1] * (len(sample.shape) - 1)))\n",
    "            )\n",
    "    noise = th.randn_like(gt, device=rm.device)\n",
    "    sample = model_mean + nonzero_mask * th.exp(0.5 * posterior_log_variance_clipped) * noise\n",
    "    \n",
    "    t = t - 1\n",
    "    \n",
    "get_combined_image(sample, pred_xstart, \"sample\", \"pred_xstart\")"
   ],
   "id": "78aa9c44bd5ad10f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 尝试自己写添加噪声的方法3\n",
    "\n",
    "pred_xstart = None\n",
    "sample = th.randn_like(gt, device=rm.device)\n",
    "t = 124\n",
    "\n"
   ],
   "id": "6ed000945710ac4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "gt = gt.to(rm.device)\n",
    "for i in tqdm(range(2)):\n",
    "    # print(f\"curr_t = {t}\")\n",
    "    \n",
    "    image_after_step, pred_xstart, out, _, _ = rm.take_one_sample(gt, gt_keep_mask, sample, t)\n",
    "    # we do not use image_after_step\n",
    "    p = t / 125.0\n",
    "    p = math.pow(p, 2)\n",
    "    noise = th.randn_like(gt, device=rm.device)\n",
    "    sample = noise * (p) + gt * (1 - p)\n",
    "    sample = th.clamp(sample, -1.0, 1.0)\n",
    "    t = t - 1\n",
    "print(t, p)\n",
    "get_combined_image(sample, pred_xstart, \"sample\", \"pred_xstart\")"
   ],
   "id": "79743ed41d983718",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 多张图片切换",
   "id": "42e2e1aadc903be8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "gt = load_image_from_path(\"./gt.png\")\n",
    "gt_keep_mask = load_image_from_path(\"./gt_keep_mask.png\") * 0.5 + 0.5\n",
    "\n",
    "gt2 = load_image_from_path(\"./gt2.png\")\n",
    "gt_keep_mask2 = load_image_from_path(\"./gt_keep_mask2.png\") * 0.5 + 0.5\n",
    "\n",
    "gts = [gt, gt2]\n",
    "gt_keep_masks = [gt_keep_mask, gt_keep_mask2]"
   ],
   "id": "6e67872baf86e434",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "gt = gt.to(rm.device)\n",
    "pred_xstarts = [None, None]\n",
    "samples = [th.randn_like(gt, device=rm.device), th.randn_like(gt, device=rm.device)]\n",
    "t = 124\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(120)):\n",
    "    idx = i % 2\n",
    "    _, pred_xstarts[idx], out, _, _ = rm.take_one_sample(gts[idx], gt_keep_masks[idx], samples[idx], t)\n",
    "    \n",
    "    samples[idx]\n",
    "    \n",
    "    t = t - 1\n",
    "    \n",
    "get_combined_image(sample, pred_xstart, \"sample\", \"pred_xstart\")"
   ],
   "id": "70a9e3c436323cbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "816d7ffe73ea49c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ad938fe03f171e4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a189f4d5697eab8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b6789910973b8e6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9b04d31c75041721",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a234997a99c05973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d33e17f905311f59",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
