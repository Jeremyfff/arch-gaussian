{
 "cells": [
  {
   "cell_type": "code",
   "id": "34ed525c",
   "metadata": {},
   "source": [
    "#加载全部数据到内存中\n",
    "def get_data():\n",
    "    from datasets import load_dataset\n",
    "    import numpy as np\n",
    "\n",
    "    #加载\n",
    "    dataset = load_dataset('lansinuote/gen.1.celeba', split='train')\n",
    "\n",
    "    #采样\n",
    "    dataset = dataset.shuffle(0).select(range(20000))\n",
    "\n",
    "    #图片转数据\n",
    "    def f(data):\n",
    "        images = data['image']\n",
    "\n",
    "        data = []\n",
    "        for i in images:\n",
    "            i = i.resize((64, 64))\n",
    "            i = np.array(i)\n",
    "            i = i / 255\n",
    "            i = i.transpose(2, 0, 1)\n",
    "            data.append(i)\n",
    "        return {'image': data}\n",
    "\n",
    "    dataset = dataset.map(function=f,\n",
    "                          batched=True,\n",
    "                          batch_size=1000,\n",
    "                          num_proc=4,\n",
    "                          remove_columns=list(dataset.features)[1:])\n",
    "\n",
    "    #加载为numpy数据\n",
    "    data = np.empty((20000, 3, 64, 64), dtype=np.float32)\n",
    "    for i in range(len(dataset)):\n",
    "        data[i] = dataset[i]['image']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = get_data()\n",
    "\n",
    "data.shape, data.min(), data.max()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbc5e98c",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "len(loader), next(iter(loader)).shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65a3f787",
   "metadata": {},
   "source": [
    "def show(images):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    if type(images) == torch.Tensor:\n",
    "        images = images.to('cpu').detach().numpy()\n",
    "\n",
    "    images = images[:50]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        image = image.transpose(1, 2, 0)\n",
    "\n",
    "        plt.subplot(5, 10, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show(next(iter(loader)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6fd60f02",
   "metadata": {},
   "source": [
    "def schedule(time, method='offset_cosine'):\n",
    "    if method == 'linear':\n",
    "        t = 1 - (1e-4 + time * (0.02 - 1e-4))\n",
    "\n",
    "        #累乘\n",
    "        #cumprod = [1]\n",
    "        #for i in t:\n",
    "        #    cumprod.append(cumprod[-1] * i)\n",
    "        #t = torch.FloatTensor(cumprod[1:])\n",
    "\n",
    "        #等价\n",
    "        t = torch.cumprod(t, dim=0)\n",
    "\n",
    "        return (1 - t).sqrt(), t.sqrt()\n",
    "\n",
    "    if method == 'cosine':\n",
    "        #1.5707963267948966 = pi/2\n",
    "        t = time * 1.5707963267948966\n",
    "        return t.sin(), t.cos()\n",
    "\n",
    "    if method == 'offset_cosine':\n",
    "        #0.3175604292915215 = acos(0.95)\n",
    "        #1.2332345639299847 = acos(0.02) - acos(0.95)\n",
    "        t = 0.3175604292915215 + time * 1.2332345639299847\n",
    "\n",
    "        return t.sin(), t.cos()\n",
    "\n",
    "\n",
    "time = torch.arange(20) / 20\n",
    "print('linear=', schedule(time, 'linear'))\n",
    "print('cosine=', schedule(time, 'cosine'))\n",
    "print('offset_cosine=', schedule(time, 'offset_cosine'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f5106c5",
   "metadata": {},
   "source": [
    "class Combine(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #6.907755278982137 = log(1000)\n",
    "        t = torch.linspace(0.0, 6.907755278982137, 16).exp()\n",
    "        t *= 2\n",
    "        #3.141592653589793 = pi\n",
    "        t *= 3.141592653589793\n",
    "        self.register_buffer('t', t)\n",
    "\n",
    "        self.upsample = torch.nn.UpsamplingNearest2d(size=(64, 64))\n",
    "\n",
    "        self.cnn = torch.nn.Conv2d(3, 32, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def get_var(self, var):\n",
    "        #[b, 1] -> [b, 16]\n",
    "        var = self.t * var\n",
    "\n",
    "        #[b, 16+16] -> [b, 32]\n",
    "        var = torch.cat((var.sin(), var.cos()), dim=1)\n",
    "\n",
    "        #[b, 32] -> [b, 32, 1, 1]\n",
    "        var = var.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
    "\n",
    "        #[b, 32, 1, 1] -> [b, 32, 64, 64]\n",
    "        var = self.upsample(var)\n",
    "\n",
    "        return var\n",
    "\n",
    "    def get_image(self, image):\n",
    "        #[b, 3, 64, 64] -> [b, 32, 64, 64]\n",
    "        image = self.cnn(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def forward(self, image, var):\n",
    "        #image -> [b, 3, 64, 64]\n",
    "        #var -> [b, 1, 1, 1]\n",
    "\n",
    "        #[b, 1, 1, 1] -> [b, 1]\n",
    "        var = var.squeeze(dim=-1).squeeze(dim=-1)\n",
    "\n",
    "        #[b, 1] -> [b, 32, 64, 64]\n",
    "        var = self.get_var(var)\n",
    "\n",
    "        #[b, 3, 64, 64] -> [b, 32, 64, 64]\n",
    "        image = self.get_image(image)\n",
    "\n",
    "        #[b, 32+32, 64, 64] -> [b, 64, 64, 64]\n",
    "        combine = torch.cat((image, var), dim=1)\n",
    "\n",
    "        return combine\n",
    "\n",
    "\n",
    "Combine()(torch.randn(2, 3, 64, 64), torch.randn(2, 1, 1, 1)).shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b707110",
   "metadata": {},
   "source": [
    "class Residual(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, channel_in, channel_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = torch.nn.Conv2d(channel_in,\n",
    "                                   channel_out,\n",
    "                                   kernel_size=1,\n",
    "                                   stride=1,\n",
    "                                   padding=0)\n",
    "\n",
    "        self.s = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm2d(channel_in),\n",
    "            torch.nn.Conv2d(channel_in,\n",
    "                            channel_out,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=1),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Conv2d(channel_out,\n",
    "                            channel_out,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x) + self.s(x)\n",
    "\n",
    "\n",
    "Residual(3, 6)(torch.randn(2, 3, 64, 64)).shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1222b1a6",
   "metadata": {},
   "source": [
    "class UNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down = torch.nn.ModuleList([\n",
    "            Residual(64, 32),\n",
    "            Residual(32, 32),\n",
    "            torch.nn.AvgPool2d(2),\n",
    "            Residual(32, 64),\n",
    "            Residual(64, 64),\n",
    "            torch.nn.AvgPool2d(2),\n",
    "            Residual(64, 96),\n",
    "            Residual(96, 96),\n",
    "            torch.nn.AvgPool2d(2),\n",
    "        ])\n",
    "\n",
    "        self.middle = torch.nn.ModuleList([\n",
    "            Residual(96, 128),\n",
    "            Residual(128, 128),\n",
    "        ])\n",
    "\n",
    "        self.up = torch.nn.ModuleList([\n",
    "            torch.nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            Residual(224, 96),\n",
    "            Residual(192, 96),\n",
    "            torch.nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            Residual(160, 64),\n",
    "            Residual(128, 64),\n",
    "            torch.nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            Residual(96, 32),\n",
    "            Residual(64, 32),\n",
    "        ])\n",
    "\n",
    "        self.out = torch.nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "        #image -> [b, 64, 64, 64]\n",
    "\n",
    "        #[b, 32, 64, 64]\n",
    "        #[b, 32, 64, 64]\n",
    "        #[b, 64, 32, 32]\n",
    "        #[b, 64, 32, 32]\n",
    "        #[b, 96, 16, 16]\n",
    "        #[b, 96, 16, 16]\n",
    "        out = []\n",
    "        for i in self.down:\n",
    "            image = i(image)\n",
    "            if type(i) == Residual:\n",
    "                out.append(image)\n",
    "\n",
    "        #[b, 96, 16, 16] -> [b, 128, 8, 8]\n",
    "        for i in self.middle:\n",
    "            image = i(image)\n",
    "\n",
    "        #[b, 96, 16, 16]\n",
    "        #[b, 96, 16, 16]\n",
    "        #[b, 64, 32, 32]\n",
    "        #[b, 64, 32, 32]\n",
    "        #[b, 32, 64, 64]\n",
    "        #[b, 32, 64, 64]\n",
    "        for i in self.up:\n",
    "            if type(i) == Residual:\n",
    "                #[b, 128+96, 16, 16] -> [b, 224, 16, 16]\n",
    "                #[b, 96+96, 16, 16] -> [b, 192, 16, 16]\n",
    "                #[b, 96+64, 32, 32] -> [b, 160, 32, 32]\n",
    "                #[b, 64+64, 32, 32] -> [b, 128, 32, 32]\n",
    "                #[b, 64+32, 64, 64] -> [b, 96, 64, 64]\n",
    "                #[b, 32+32, 64, 64] -> [b, 64, 64, 64]\n",
    "                p = out.pop()\n",
    "                image = torch.cat((image, p), dim=1)\n",
    "            image = i(image)\n",
    "\n",
    "        #[b, 32, 64, 64] -> [b, 3, 64, 64]\n",
    "        image = self.out(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "UNet()(torch.randn(2, 64, 64, 64)).shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a9b957f",
   "metadata": {},
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "\n",
    "\n",
    "class Diffusion(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.norm = torch.nn.BatchNorm2d(3, affine=False)\n",
    "        self.unet = UNet()\n",
    "        self.combine = Combine()\n",
    "\n",
    "    def forward(self, image):\n",
    "        #image -> [b, 3, 64, 64]\n",
    "        b = image.shape[0]\n",
    "\n",
    "        #对图像正则化处理\n",
    "        image = self.norm(image)\n",
    "\n",
    "        #随机噪声\n",
    "        noise = torch.randn(b, 3, 64, 64, device=image.device)\n",
    "\n",
    "        #随机系数\n",
    "        #[b, 1, 1, 1],[b, 1, 1, 1]\n",
    "        noise_r, image_r = schedule(torch.rand(b, 1, 1, 1,\n",
    "                                               device=image.device))\n",
    "\n",
    "        #合并图像和噪声\n",
    "        #[b, 3, 64, 64]\n",
    "        image = image * image_r + noise * noise_r\n",
    "\n",
    "        #合并噪声图和噪声系数\n",
    "        #[b, 64, 64, 64]\n",
    "        combine = self.combine(image, noise_r**2)\n",
    "\n",
    "        #从噪声图中预测出噪声\n",
    "        pred_noise = self.unet(combine)\n",
    "\n",
    "        return noise, pred_noise\n",
    "\n",
    "\n",
    "diffusion = Diffusion(PretrainedConfig())\n",
    "\n",
    "_ = diffusion(torch.randn(2, 3, 64, 64))\n",
    "\n",
    "_[0].shape, _[1].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee6b27e5",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def generate(n, device):\n",
    "    #从随机噪声开始生成\n",
    "    image = torch.randn(n, 3, 64, 64, device=device)\n",
    "\n",
    "    #生成20个step\n",
    "    for i in range(20):\n",
    "        time = torch.full(size=(n, 1, 1, 1),\n",
    "                          fill_value=(20 - i) / 20,\n",
    "                          dtype=torch.float32,\n",
    "                          device=device)\n",
    "\n",
    "        #随机系数\n",
    "        noise_r, image_r = schedule(time)\n",
    "\n",
    "        #合并噪声图和噪声系数\n",
    "        #[b, 64, 64, 64]\n",
    "        combine = diffusion.combine(image, noise_r**2)\n",
    "\n",
    "        #从噪声图中预测出噪声\n",
    "        pred_noise = diffusion.unet(combine)\n",
    "\n",
    "        #根据预测的噪声还原图像\n",
    "        pred_image = (image - noise_r * pred_noise) / image_r\n",
    "\n",
    "        #再次计算随机系数\n",
    "        time = time - (1 / 20)\n",
    "        noise_r, image_r = schedule(time)\n",
    "\n",
    "        #重新向图像中添加噪声,以进行下一个step的计算\n",
    "        image = image_r * pred_image + noise_r * pred_noise\n",
    "\n",
    "    #根据正则化数据反正则化图像\n",
    "    mean = diffusion.norm.running_mean.reshape(1, 3, 1, 1)\n",
    "    std = (diffusion.norm.running_var**0.5).reshape(1, 3, 1, 1)\n",
    "\n",
    "    pred_image = mean + pred_image * std\n",
    "    pred_image = pred_image.clip(0.0, 1.0)\n",
    "\n",
    "    return pred_image\n",
    "\n",
    "\n",
    "show(generate(10, 'cpu'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "222669de",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def train():\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(diffusion.parameters(),\n",
    "                                  lr=2e-4,\n",
    "                                  weight_decay=1e-4)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    diffusion.to(device)\n",
    "    diffusion.train()\n",
    "\n",
    "    for epoch in range(2000):\n",
    "        for i, data in enumerate(loader):\n",
    "            noise, pred_noise = diffusion(data.to(device))\n",
    "\n",
    "            loss = criterion(noise, pred_noise)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, loss.item())\n",
    "            diffusion.eval()\n",
    "            show(generate(10, device))\n",
    "            diffusion.train()\n",
    "\n",
    "\n",
    "local_training = True\n",
    "\n",
    "if local_training:\n",
    "    train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8be22819",
   "metadata": {},
   "source": [
    "if local_training:\n",
    "    #保存训练好的模型到hub\n",
    "    diffusion.to('cpu').push_to_hub(\n",
    "        repo_id='lansinuote/gen.9.diffusion',\n",
    "        use_auth_token=open('/root/hub_token.txt').read().strip())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "42a3baac",
   "metadata": {},
   "source": [
    "#加载训练好的模型\n",
    "diffusion = Diffusion.from_pretrained('lansinuote/gen.9.diffusion')\n",
    "\n",
    "with torch.no_grad():\n",
    "    show(generate(50, 'cpu'))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt39]",
   "language": "python",
   "name": "conda-env-pt39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
